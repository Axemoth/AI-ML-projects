{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Axemoth/AI-ML-projects/blob/main/yolov8_with_webcam_and_user_upload_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 1: Download AI Model Files (PyTorch Compatible)\n",
        "# Run this cell first. It downloads the pre-trained YOLOv8 model weights\n",
        "# compatible with PyTorch, as well as the necessary configuration and class names files.\n",
        "\n",
        "print(\"‚¨áÔ∏è  Preparing to use YOLOv8 model...\")\n",
        "\n",
        "# YOLOv8 does not require separate download of weights, cfg, or names files\n",
        "# when loading directly via torch.hub or the ultralytics library.\n",
        "# The necessary files are handled internally by the library.\n",
        "\n",
        "print(\"‚úÖ YOLOv8 model setup does not require manual file downloads.\")\n",
        "# The following line is commented out as it's not needed for the webcam/upload functionality\n",
        "# !yolo task=detect mode=predict model={HOME}/runs/detect/train/weights/best.pt conf=0.25 source={dataset.location}/test/images save=True\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "# @title Cell 2: Capture a Photo from Your Webcam or Upload an Image and Run Object Detection (PyTorch)\n",
        "# This cell combines taking a photo or uploading an image and running object detection.\n",
        "# It uses your browser's capabilities to access your webcam, takes a picture,\n",
        "# loads the PyTorch AI model, finds the objects in the photo, and draws boxes and labels on them.\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow # Special function for Colab\n",
        "from google.colab import files # Import files for uploading\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture button to be clicked\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 20, video.videoWidth, video.videoHeight - 40); # Adjusted y and height\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename\n",
        "\n",
        "\n",
        "print(\"üì∏ Choose an option: Take a photo from webcam (type 'webcam') or upload an image (type 'upload').\")\n",
        "option = input().lower()\n",
        "\n",
        "image_file = None\n",
        "\n",
        "if option == 'webcam':\n",
        "    print(\"üì∏ Running this cell to take a photo and run object detection. You may need to grant camera permissions.\")\n",
        "    image_file = take_photo()\n",
        "    print(f\"Photo saved as {image_file}\")\n",
        "elif option == 'upload':\n",
        "    print(\"‚¨ÜÔ∏è  Upload an image file.\")\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        # Assuming only one file is uploaded\n",
        "        image_file = list(uploaded.keys())[0]\n",
        "        print(f\"File '{image_file}' uploaded.\")\n",
        "    else:\n",
        "        print(\"‚ùå No file uploaded.\")\n",
        "else:\n",
        "    print(\"Invalid option. Please run the cell again and type 'webcam' or 'upload'.\")\n",
        "\n",
        "\n",
        "# --- Proceed with detection only if an image file is available ---\n",
        "if image_file:\n",
        "    # --- 1. Load the Model and Class Names (PyTorch) ---\n",
        "    print(\"üß† Loading PyTorch YOLOv8 model...\")\n",
        "    try:\n",
        "        # Load the YOLOv8 model using the ultralytics library\n",
        "        # Need to install ultralytics first\n",
        "        print(\"Checking for ultralytics library...\")\n",
        "        try:\n",
        "            import ultralytics\n",
        "            print(\"‚úÖ ultralytics library found.\")\n",
        "        except ImportError:\n",
        "            print(\"Installing ultralytics library...\")\n",
        "            !pip install ultralytics -q\n",
        "            print(\"‚úÖ ultralytics library installed.\")\n",
        "\n",
        "        from ultralytics import YOLO\n",
        "\n",
        "        # Load a pretrained YOLOv8n model\n",
        "        model = YOLO('yolov8n.pt') # Using nano model for faster inference\n",
        "\n",
        "        print(\"‚úÖ PyTorch YOLOv8 model loaded.\")\n",
        "\n",
        "        # --- Load Class Names (for PyTorch model) ---\n",
        "        # The YOLO object has the class names\n",
        "        try:\n",
        "            classes = model.names\n",
        "            print(\"‚úÖ Class names loaded from model.\")\n",
        "        except AttributeError:\n",
        "            print(\"‚ùå Error: Could not load class names from YOLOv8 model.\")\n",
        "            classes = [] # Initialize as empty list to avoid further errors\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading model: {e}\")\n",
        "        model = None # Set model to None if loading fails\n",
        "\n",
        "    # --- Proceed with detection only if model loaded successfully ---\n",
        "    if model is not None:\n",
        "        # --- 2. Load the Image ---\n",
        "        img = cv2.imread(image_file)\n",
        "        if img is None:\n",
        "            print(\"Error: Could not read the image file. Please make sure you uploaded a valid image.\")\n",
        "        else:\n",
        "            height, width, channels = img.shape\n",
        "\n",
        "            # --- 3. Prepare Image for the Model and Run Inference (PyTorch) ---\n",
        "            print(\"üèÉ Running PyTorch model inference...\")\n",
        "            # Convert OpenCV image (BGR) to PIL image (RGB)\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Perform inference\n",
        "            # The model automatically handles resizing and normalization\n",
        "            results = model(img_rgb)\n",
        "\n",
        "            # --- 4. Process Detections (PyTorch Output) ---\n",
        "            # The 'results' object contains detected objects, bounding boxes, and scores\n",
        "            # The format is typically a list of Results objects\n",
        "            detections = results[0].boxes # Get the Boxes object from the first result\n",
        "\n",
        "            class_ids = []\n",
        "            confidences = []\n",
        "            boxes = []\n",
        "            print(\"üîç Processing detections...\")\n",
        "\n",
        "            # Initialize colors array before the loop, using the loaded classes\n",
        "            colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "\n",
        "\n",
        "            # Iterate through detections and extract information\n",
        "            for det in detections:\n",
        "                confidence = float(det.conf)\n",
        "                class_id = int(det.cls)\n",
        "                x_min, y_min, x_max, y_max = [int(x) for x in det.xyxy[0]] # xyxy format: [x_min, y_min, x_max, y_max]\n",
        "                w, h = x_max - x_min, y_max - y_min\n",
        "\n",
        "                if confidence > 0.3 and class_id < len(classes):  # lowered threshold from 0.5 to 0.3\n",
        "                    boxes.append([x_min, y_min, w, h])\n",
        "                    confidences.append(confidence)\n",
        "                    class_ids.append(class_id)\n",
        "                elif class_id >= len(classes):\n",
        "                    print(f\"‚ö†Ô∏è Detected class ID {class_id} is out of bounds. Skipping.\")\n",
        "\n",
        "\n",
        "            # YOLOv8 results already include NMS, so we don't need a separate NMS step here\n",
        "            # indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.3, 0.4)  # match confidence threshold\n",
        "\n",
        "            font = cv2.FONT_HERSHEY_PLAIN\n",
        "            print(\"\\nüéâ Detection Complete! Displaying result:\")\n",
        "\n",
        "            if len(boxes) > 0: # Check if there are any boxes after processing\n",
        "                for i in range(len(boxes)): # Iterate through the valid boxes\n",
        "                    x, y, w, h = boxes[i]\n",
        "                    label = str(classes[class_ids[i]])\n",
        "                    score = round(confidences[i], 2)\n",
        "                    color = colors[class_ids[i]]\n",
        "\n",
        "                    cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
        "                    cv2.putText(img, f\"{label} {score}\", (x, y + 30), font, 2, color, 2)\n",
        "            else:\n",
        "                print(\"üö´ No objects detected above confidence threshold.\")\n",
        "\n",
        "            img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "            cv2_imshow(img_bgr)\n",
        "    # üî¢ Count objects detected\n",
        "    object_count = {}\n",
        "    for class_id in class_ids:\n",
        "        label = classes[class_id]\n",
        "        object_count[label] = object_count.get(label, 0) + 1\n",
        "\n",
        "    # üìä Print object count summary\n",
        "    print(\"\\nüìä Object Summary:\")\n",
        "    if object_count:\n",
        "        for obj, count in object_count.items():\n",
        "            print(f\" - {obj}: {count}\")\n",
        "    else:\n",
        "        print(\"‚ùå No objects detected above threshold.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚¨áÔ∏è  Preparing to use YOLOv8 model...\n",
            "‚úÖ YOLOv8 model setup does not require manual file downloads.\n",
            "üì∏ Choose an option: Take a photo from webcam (type 'webcam') or upload an image (type 'upload').\n",
            "upload\n",
            "‚¨ÜÔ∏è  Upload an image file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-22fa5b26-8104-4700-b1c7-a1ce821c62c0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-22fa5b26-8104-4700-b1c7-a1ce821c62c0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving img3.png to img3.png\n",
            "File 'img3.png' uploaded.\n",
            "üß† Loading PyTorch YOLOv8 model...\n",
            "Checking for ultralytics library...\n",
            "‚úÖ ultralytics library found.\n",
            "‚úÖ PyTorch YOLOv8 model loaded.\n",
            "‚úÖ Class names loaded from model.\n",
            "üèÉ Running PyTorch model inference...\n",
            "\n",
            "0: 640x576 1 person, 213.3ms\n",
            "Speed: 10.1ms preprocess, 213.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 576)\n",
            "üîç Processing detections...\n",
            "\n",
            "üéâ Detection Complete! Displaying result:\n",
            "üö´ No objects detected above confidence threshold.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=76x85>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEwAAABVCAIAAABsLJUvAAAfGUlEQVR4Ae17CXBc13XlX/r37xXdDaABNHYQAAlwEQnulCWaomTZlE2aUhRnHJeXOOOaqkxSqaRclcUpV1kVeWrGiWc8jkelih07dCTbihQyshbSIilSokSJ4goQBEHsC7E00Gj0vvxtzn2/F4CERJCilCrPvPp4/f7b7j333nff8h94wzC43/Yg/LYDJHz/H+Rvi5b/n9CkpaAtleMseR+k8QafM2XK0plVIwdPIegch7J8tUL2TQmzTx6dUH084uJ+bmpw9zOKmgRICownRHqOJWIM/JksmlXMeMnMhRUWpQ3qTmMPUaBeF5V/pC98YQoB04SY0TZ4kwtDYwithJGCpmSzqZSWTFsUlU+kOFUTDDGbyNiqA6K3hHM6io4MKkYfZszaUsc85RWoLDIMVucjiormCtpQJswUCVgU4IEhjYMUdC4bM+LJeN/gtdffkCZnk+OTdlnmZavL57U3NNmqG+yZ7ODYiOh2OlubS2sCQokb7Oo8UAh8Hid+AZFi+vtYQ1GTIJtlpIFQ5KBDXed4JPRo1PL2WxP9A6Gh0eD4uMNqa13Zanjc816HXOrlJWc6kvbZ7OUVVenZ0Dtn3mnfvqXyoV2c1YLeRE4EInpIj/nwHwtSYbbEeID6YKK8JZMJvnsu/NpR1dBLKytcnhJbVaW0brVqk3RJFK2SIMh8IjM3NJLsHaiqqVOTibiSTbvtNRvu0UtcgGmig3UIBZw8mQzl5FF/1L9FTULwVlAzCJwO72oYUOPs6bPjp884ZUdde5ttXRvntCl2WRcEaBv1SEVMTWA3Mzs3dvZCtccnuZzdXV1ZXVu/c6dcVwujpQ7ZEKBWgMqTyTB7+ajR5fovgsxwnMyEDR8IiKJuKEPDZw++VF9aZnt4V6m/QrBK4C/NGtoQUz1OFww8xZENNAYX6xt85/DhgL9izf59vMNGTpXPo/qPALmEyRCf8PjTM5ePnVTTaffWDnttTUaWwCiCzaAHqoiK3JyFS/G8RSfTS3N8mhOgZEMQ3I0NG+/fOR0KT3T3kMJNf8OkQ5HBQShLEC5UuNuJog5yVJmXx9ww/u65wbfPfGLfZ0vampnF5SkzqDBssm0KZK/g28bzGNJQmgClyVJZxz2rXY7e1163WKXKe9YWxqPZ5uNECIpFkBJjJMPpIvQ4NNx3/szGPQ+Uf24Xb8HweX+uGEaTdcn8QcwyA6ta1FT6xKFfb5oNt9x/r2oV0zwZtoWKP9awmHueA6NwiEMXL8pud1Nbm2Sl0XfHoa61pW3N6nNvvaWFw0AmAh481ceNcaGKmFOBo+fnI8P9Ays23MO3r7xjeLmGdtv6Tz1U19Q4PX5dULWi2aD4Y9ysL9CkQSOKy2Snzl0wVLW8fRUnmVzdueTJJbmcdc0rLpx+JzUd5LMKsN0wPj+sHJfRfgFIqq1zwZnhKz1lFRXWkhJmV6hw5yCzWFMIXN3mTQ6nMzQ1zSmqUAR5590uA9eiKgtBGnZdn8PybXq6DesVm4yFK1AXuVrUcFkvPC+QiCziyjXtly9dwvwr8EKO5MeHcdGY1JXZUN/FS6IsOxobeEkibshP3Dk7MHfMrjBaX33d3Mxs96m39AwmGjYuliWlu1OpqElsO+K9A6GJiZrWZr68lEfAggZ6/BCDCI4aywaF5+QK/5oNG652dk70XsOk+jEPy4UgOW52zut2t65pp80DMQLbgrv9UCzBmQGnyvOYSwxV6+u6jH4/VI+3r12BCDKaeio5PjpiKS2zlpax2R9WSoYqLDTpmwnkm7N+8IINms62abQ6xG4DKwksM0Ret1X4yqrLr3df0hLzGU7Jchrws6VusVNqz55i1t1IFTWpTM5Mzc3Vb97E+St04g1FBJLtopdPCsadt292gmLHio9WOQYnC9s//2m3lZ+6eF7kFAwFEyGT8KL+b85ZVHz7L8z7Mc8yNzySyWar2lYaVusiMqz01j2bAiFDF6F8pn+eFnq55vjh7b6y8rra/rPn7OkkiiBF8yl0TpUKLQq5HzpR3MqmRsasdhtXUmIazCKcyyADy8zjWVA73wv6xISEeMWWrS6bnZuLwKvlTCVfHXXxACTy724QwByZl8EpoxN2r8eknOeNaNEy6IMC6oJ5FlgSvcEWse3MMhAoo+NNHghBSyxtqJ+YDnYeOY5zsIVnIrei8kEc3LKMpAYeRrq6E7Ohyrragrkwzqg5Sj8o0GaRzkpoBZiXDdoSNtYMe3HMjJhtmQGLstfXtG7dxc5OPRKh8nwTJAtNWLu7GTHvCg8RT8pW2dfazBgitwPqZIHLMx7aWSxgF51asGUDOp40hBIdf7mtM+9raeFkeWp6utDko4PHENAWl+PSmeHOyx6f11dTDWagG0ziIAzAiAusmA2WjAvbJyxuBF63Kqnw1a7rL/27FokJTEOwYaZy9Cn6G+qrGhqGh4aNTIY6x/MRB4EGRiwx2HlZdDosTjuRY4QBz9TkrZiAlHJqVHkOXKtAFQq+8fRTL/z5N6fPX5SZLZhYEKNPq7ukqbExHospGSwTCgRvRcesekcx06Ru6ImkjrWzNX+mkad9W33SMpW8GM5wRAfHtUpicmh0iR543l9ermQy8Wh0idKPIAvzpMZd76kPXlXlEriPLCdobPOOjz+YxMlccwbHaXCbHBdHDunF1LRp0YIK36lwMu2rYK0SJ5U2rLu3xJbmQ4NwzwqnY/mKRY/EY9+M4Ska3oC/PMDNh7DuifMYvWhDnRMJg0vdhBMEQQ/jO2dcN1X44AwLrE2JRpOJhMGUSkM0H5gh0gvIwxXBf5oOibJ4yoRrZofHBnRoIT+N0xODftFSFGrKyuID/ZyicBbYbG7sgR5W/r7GulV6NjE7W8K6NUtB36QIKjeEAic35C/zlZAlYjGrRZLZLrnQnZlAjAARQpYUDHZIx+cmT3z/4XQIl74LmQxi+UYgBS5rqFBsYmKSm50t9IkSs0PYc0lZGSxWUBSae1hAQ7PmjSDJcBY8+frL/yWWQjMzIg5LA5VIm5SoPWOHipcKKgMzdrU32NnFJeOYM2CQZMIwK7gyHENLkp5VtUh4/vp1zKPUGe1LUYmS0HxG06LRqBqeB4mcBBkhVoml7l4E9ox0MlVdWeWqqUa3RZAmTEYfwi6gBRAYKgphqP60Ovj6ibHXj4npJLLw6ZYYRmwRS6sDBm8VYpHRK5fFVAqskwQIJP3Aq4o+D1aRuqqgZ9PJmlBREzmwHdRn3ZkLJsYNyedOAryKkU4kPE4nUWM7jjxDNALNAJ+bS7NvNcgkzDo3dO7Sz7/3/Zd++P1gz2Xsp1SyfZNVwVNVI5YF9FQ8cv26RTVtEqU0ItGUUpKUiCfowwODxH6RzAXKXRBMtIANE7iDAJCamlVkyaoxx7NQacXuGOdEg2UBsEmr1OezplPp0YFYVydKzFIGkxedLmtVLb6n8FkcKRtQO8kFzfDQZwKsGvBBCbLDL+t04bcDVGYPbMJsgRomTrMua3AbkcBpOmA67HZRLk6SZo/UzeJe8UZbJPOwQOD8a9rWd6y2ZxIDx49ngrPMIBltMCfapLIKi0VIzM9z2Sz6QWlhAjBFaeUFJRpDEZmJicqkCDKobTLBYqCFjPCYwmU0biMS4OvdLre7ri4DX2+GgvRu6IdRMMcd4eE524rGTds3eXktfO1aOhTKaZK14q02S2mFIInTk9e5eBx5aIIK+TrgnbNoxnT/AMAAM76+pCOReHAmMTUVHR2butLTd/rd2OQUh4MvWvgSZtDPjRp6v41gQe92XUhPh6wuCzYTtFdgfS7qg8EzZWkakMzB+WuizeFtabDyCXXySqjryIq1K1TdalqaQ9TjzoDX6bL1nE9dPGM0tmLV4SCMYoKzOGGqOucur5ge7K5VEmLSwo0M22bG1aFhS2yeq6koyVhmjNj06EVVk7ytq/jN2zlBhH+CHmBvpkoR3xBgKXjALIogDqrAsFjQOK2o0WTaphVHNQN1Qw/FV5zfYULHGRcd6OGrlac8HYqeeeFgzb4vS7IPbfENV7HxqWpP9cq2sb7+yaH+AKZTOnCljnPM8bon4Ey+1aO//ItkXJ7u6+IzMVnnHYIU7b0s1rZUNtVU+P3J85evXr5aOTtfeu+9osejYO0J4u9jt+iZjCK/qCBzYzAtuiTxdvtMYqwmlV0C2xJZmHQIpCiS7VStWDNS2qJkh4Z7eib7rzWu2YZMhTcwyj1rW7We9Xxv79CFc43JuO72qrxg4TQZfULAvM6n5iKd50+fOCoHVq3esTWhekRBdgbqE6GQb1PH8HtnOl85zMfS1Y1NvQdfFl/8zcov/Z5z52bRyPuOm3gDyJwECR3TIquD72h8WW3tSF+fkcJunkbOTW1ZiwURdFh4k0rKrJzDAW8ampg59ZvGdQQSB+XoR7bYLPXNZV7v2OR1IRjUnT5N4Cx0qI5C9MBPXemNz0d9Tnfdhi2OXQ85yss4Vyk2KbVYUYnqmo5NrZ/c3fXaUZGXdlTWdR498e5z/7pzzQqprIpImBgWoypwZSYKXNIlrJLa2gzOy9PkeHL0WRdm+oaWN7zyleWOLRvkrog9PvPWT56u3bIr0H6P4fJg8KlZCSeAzU0toSvX4hcu2BtWwc50AonjHgGjZ2Y8FBSdG/bsF3c/ytUG4g4HyNO4ooWxpUywWNvXdqxs51IZgF7dvi7+y1+GL/QIDxFIBCgDTw4JG3u5XFaai1g+uQl7Q+NkJhMbGDSHqdkepcUxurDZ4nTWW1r2X/8k8MXf2/Tgjsfqy9/5m78Y+senpGzKyelTeiIxO+PBLLNj59nDR8S5eSt9XQFjBlyIpiSt2Qjvtbsf3+dobso67LKh2w3Na+jlnBZQOasOYQgZUcq4XEqJ3bK2ufnB+8WzF8RUBncb8MBq6TQQwURYwGlmmiUkVsx5IGqV5KrKSP8QakN7hcqUIJYWNLopaZHsFZWNYstm572fqd31yPrKys5f/cvg/3pSmuip5IKyReFWri3Z/eloMjl1/DecYl7aQ6fYs0UHL1+04wTTJkOxFh13hnDjAKpROT5DdOkuhWbndDwCr2V5zdNamxnqV83zhPycBHlloHk8AhJGmjPYxh1M0wEw1iGCzs6fOLu9sqEx1TdOs7YNu8jbCBh8AkzTVdE3El65/d6mypZk5Zmj//rzyb6zOz/5gG7nudoGa33j6q6e4YvnqjZu5FpbCBJB4PVMZmJonDt6nHv4S4LdGuVxYAspC7DVEnJqOImnPS0NcdTHBG23ZQ0to2RtTEosInM1H6YMtnJm7IeHR5R4Ih1PQCgWjAHBbq9tXhHsHpqdnHI3NZqaQwyt3nJY6hAUb8gux3RY98zzlZ/au/a+Txhl8ptHXgx3X1pz3w5ekJrs7tqtW67+w/+efO1VybK3fEUDVpCGpnisYiI0df7gcw1VbaUdHZKMOZZO/izm5z2cYtJSGXMGuKZrmyovSvV1Ii4RMRaZstkdKFXjInEjlVJnZ+d6r6bTKdnjzghC/8S4xWEvC1TyWZ0uJamzMwP/8E/c5rWtex/RIDmDNhlEQ8CFFuyeIKylgwpxYwGhq4muQdHvt1XhcxgGUyzU2xU+c7Z6VYu0/RFiOh3vfOqHnWfP22vqHvvKlzAkr599b/jkMYeeHZ2eTAnW+/ftcW/7hKe9Q5W9Gp3B4xgBDOA2EcEAHoCMD12bf/HF8obVFqdTTyaBdG5uLhGNBoPB+XBY1XXZ4fBVVtbU10OOckW5gCMrn4+TxOJlpYEfPq2IfNsffT0JrnXBASWiX5FzkcOjOfaDQyqVknGrkAXU1DQtm81aBVGULZquYL+qDPe/+eKh4VdfbvI6rbxmWLwdn/995/bN42+fHPzFU+PXLuuta9fte7Tl8S/r7lLQs4M8duAZPptIYhxlo+HBwy+OHzvSaPGXVPjjmYy3uiqZzdh9Xs5mLa+vk3BoHAhwZX42yAtul7gugpx46fDE+Ysb/8vXsv4KqA7uC6MgI3LyMkDq9PEGSxr6WA6Y1DFMXaezMawwNEPHqYdkqMpMsOfIK8PdF2XZ4m1cteGzvyuXl2OqiVx6u+/fftn93qXZuWjr6ntqV6+2Vjd6S7x2mzMbScRCc7gklI3HpjvPBngtsfNBf10tPL+vsV7A7RSXw7BKvMulY3FCo5cZHaL88QUlC99YYyOjJ77z39Y9/GDtY59XrBYRe15YLDWiBafJ95IxekAwEQJYQZmoDEvHTS2yDEMHo2zNpXHpOJmg5NIMCefrYFfmDauWMiamx3p7r719aj40Y3eUV9ZU2+xOt6tEkK12u82YDUWGh5rgt/buFeGQmQGbjgP8wcdCzGCYnamSbcP8UAp5g/UiSDWdOP1XfyvZbdv/9I9SleWoaDbASRwWuEvCWzITgAv5cBcY2DiDg3ZpRkYBrQLAE47ndAlltKnkkiJl4iMfUwB5Mmw4qSoMhGYVdGgY4fB4d4/NKvuxWM/ZSp4OUxobXrlxZSJEMSqiPdE1g2pzVK9aFZ6aykxMAHqhHzbs85Xe/5epk+AVzBUJXAgmnWFMoyS3Y2J16CCUx8rGDDjjw+jAbKTMx0KDwwL0jlLwRt/+cJuNLrRFsxmnrcTlr1mCBbYjhbQKYJAowDP3orlW6KukfSWGUdebp6yKml8Fo3aelyW6L2YttNJCGt6RplH4W2iSnTyAOoyWbZeYapmcoUiZV8VMZvzkySsHDhjHjho6kwC0AykZ9GST6fDkDBwojA+qxqpCZTF5DuiZPUznxBJ6BRWCzVRUAE8F/q0d2/fuGR0f1SYm0TE4AykaSHcaTLMhq2CCxSxICUPDUiYzMhq90ku8sSNc1ITyKmq8Zdb4yX/5n6MXTjMTJqs1m5aJohabVzCz4b2AZgFjLHvB+4JkESStA+1y2bZNoiQNvnEKV7OQQbTJvu4wgCPGVI4B0wkTMF1PDlzte/WQPjsJ1wNz02DRmiqWeku9rt4LZ7pe+BURx6hkhiQkk8nr1yXYhRMyhwvNPXRZjz2oZWbeyCgrL4LEsCFIFeVr16+7cv68GgziDYL8MCBxBx3umfg07SlnseiUd4pqdn4UV/gB0mYIssIp04lY/4Sft7b5/L2HXxk9cxqtwJXFMFLYlJ45I2dSVntuTW7yRezlA5l2Pr3wF5lFkIKmJ1GPt6z49CMbmleNHz/JzczIuKaBtSQBzSkUbSALZEHReOC+PyDgWjNK8YcHOoWXJvOAg52dVvVYSXyWH5/mVMsk5C0o1lQoPjqqt+9u+sbfbQisOfTtJ4ZOvcypIS4dunz2nWA2K23c6BBp8mB9sCFnvjBDAZIiGDOfxTfkk0tI4IK421G1YV2wtz9+5ISYyhKbJkKGFEMZ0iWHaU5BC7pbIonFABMKSYhZDo1w3G25Pq3PRLLhRO/pt+A78X8nSjiYmJrI2mR5/erG3923fs9nBodGnvmLb4/+8Cfx51/hRqfXVjf4a+reB8gSlBdmLQDP8ziewlkW1izWtatdPt+Vd8/GL/aALaYK8mDFlmxJSb5zQV6x9KYULYPZbIalhTEf0aeCQob3+CqvdV7ghq951WhqfGQmGPRUVnAlTojQ/8Uv7PvyV6Kx1E9/euDAzw4kVb28uYVzYv2wgOGbqLxfRnExAJFjn0qrMJqhdUvv0OXnD4ZjsS1f/aJt9Sq0Z5pAKR3n0RReCMxaCm+LEvheSeOR4lykpucvdZZEomKJIz4+/LMffH/ztk1bPr9XGZvrHp9t3rHDvX27xmNPqTh1XR2biI+MJZOJinXrxEAAuxBIylyiLKJyq5ciyATHOWm+5nEMhT2oBdfqpqevHHw52Ndfv3/Pqo4NgssFoPh6SV6PmSuGGaXyILEeKKwEcnQxZE3RoyqNTyM6PDjcc6WqqtLTugrSOv633+p6/bVtHR2btj847/ZXb92m1dVhoYfTaBuTDzMfrJdoyQQvDIGxe423grW4vKh9xi7xS2dbmLOwuA5Urn50L/7z4dCT/2Pg0EtcGqsx6BCkaD0O/skC8wjR8EaEyEKnqACEzOS10dGRC52e0nJPa6vm9ijukp379tevXDU8MDiTzlRt3cJVVeKoAEsFiBMCxAUDCBS2YwoTn1vMi/KLIdz6rahJsIHTNHBv4qY7xrSeNJSRiau/en50cNBeV712z56K9lbs0Jk+iXesGeCEloDHSNMQoC5xKVqNj411n34nNju3/dH9rtpqhUaXIaXmZy68N3z5cqBja9XW+0nxBrvHRZ+PyIdjXNADSghmbPLHMpYZLQJJH7aIDPVLrLEJjpY+ipYYHn7zhYMXL12yl7i/8Md/HGhbiS+QIKqThdMWZEmcCqdKMOL5+YnOS9cGBnDrrGV9h6u2Qbfg4zp0TEtbGCRh4HnsTaB17CQgNZq1mI3A7eVMgQHC7EXfxm8zFEFGYCSAB3AI7JDL9BlIqjgSRO86d/3U6Zeeez4cnL3voQdbtm+tamrS7Ng8GDhoXhJkIjHnGJ2Y6Lkam5tztTTVbt7IuTzoCRrGGgekzP1HGVJ4IOICAMBmbBAnrBBvtMrH82E0mWb/vZMzCeYSQcCkxQyZNAwujEis/933Xjn0Iq8bLS0t92za6Av4HV4vj+1v4dA5kUjFE+H58Oi5d7jJmWQs1rb+nupPPYg5wBDBKt11M6UJ2wEGh8l9ASHDUgCJQrpbjAtQOJbBBkXTLdjtMs7gPJBAjJBLLOiEclkoajKfs/SvKU7WM41+LZ5KT0xN9fYNXb4UnZtR8blaUXBD5vp0sHegH3tdp9PVumqlnIkff/GlVFbp2PnJr3/rrytaWw2LBQZCajOdCaM2Px/92c/++ciRI/FEPBAIbOzY+Ojjv9PauoIK80wTTI6LRCLr2tcnU0kcr1hESzgSRuU//Poffu1rX3E4bFQ5X591nI/QeDlBM4ysYWTYA0iQqIEspDKqMTicevfsxG+OHf3Bj/7pm996pHHVRofvUw2tV399JDo8/KM/+dNPVgQe27hl/MpVQ8FpE3SRb24mdOP//OhpyWIrK614+KHP+LzlUPPO+x4Y7B82a0J1BQ4VRXls/xdkCf+M2n7stZN4Kv01stX57b95YjY4R/WXCtDysgKaA1EBp8Iwgrquadg9GEiB/3gqPhn8sy9/LWC1b2lsiYxOQBA9b7y9rrK6vapmZmJS1fDFl4FEfWpMaK90965bu8FfXvWTH/80Fo3/2/OHamsa8K+ZTz/14xxINAF1Fa0hV+Pvv/cDi2hzOb1Xu6+h/4vnu6oD9W6XDzjfD+TyRjHbMsEHwlDh/cz9NC3TMWsLQgZfDgXseXneaXNW+uNWKcEJQ6HQdDgSV7WzfYN9M6HpRMrm8eKLPfkncEojyLR97tSpN3uvXW1ubvrc5/Y6nY69+z73jW/8Z9xmfP314zlrYxXNr0xoippejxeHg/OReczX69ev/ewjn43FY888+0w4HMkb6KJfWjDfMpibOpoWzYA1OjN9c6AiCd9LAe8GV19WZcM5ayy296GHI1YpORfmBdFqs0GH2PJRNZopgJHSUGVsfo7XISIckbohAfjp8NwMzLL32rVsVrHgizzboJF4mIdJJtLZTBb+HLo1PV15GSycw+lrPB73lXqIxOKwLJDw+OAItBAvbIBXPMCOSZxw4gXVZCmRybpdnm/+5V8mef70GydfOPS8VbLYbTKZDWrztGAy22K8zYXnEAeD0xPj4w1NK4CktbkFMTCoOIXBlaDFQbbJiqrgjBfBLPH7/VbRWlVZ5fV6F9fNvS3keckKlMmYJ/YQYKXg1bTyQj6KwDeTOB3V4pDaU1O1/6u/X17qvW/7ppOnXoczxfDFBQUGknXEIiik1FcKdSE/GolSnmHU19dB7a2trcCTTqctEsqLfFqtFsDHvwpB26iOATswOKBoSnNzM6YWXIByu2ERJmuMRp7b3Mv7/WAo4sGYLMCjmkBGYxXLM5w0sVmUtIT7uvhCp4ej84qmYuPm8ftg3MG52bHrY9PBqf+0f++XHvsdnO2bYsIc9+ij+3EzFPusU2++qSrK1OTkgX8+gNL9e/f93X//3gM7dz2+/7Hw3FyBN4EXoTEoeWoqiMzh4dHDhw8D2IYNGw4c+Hl7e/vu3bsHBgYK9ZHI0VqYdXPaxAaDxGOmC3XwCu2YRWacisdwMwgHxMloFONuYmoiEo1q8MK6NjY2duzosZd//VJvb1/OPgyjqaV127Zt0Nh3v/vdn/74x88/99zBQwf95f4d9+4YHR09c/a9V159dS4UKlCcnJrCLaesmj1x4sTY2OSzz/xiZHRk9wO7/+APvopryaFQ6MKFC9O4Fr0wwF/dxTA4OAiOIVfY4Xe+8x3Y1TPPPFNeXu50Op988snu7u6HH354x44d4A8GaQZQHxkZefzxx7F+cjgcK1eu3LNnz7PPPosJA3FbWxvstqenp8Dkrl277HZ7WVkZ/C267ejoeOKJJ3p7e0Hr0qVL6Hzz5s2dnZ2F+kgsd8WzUC4fnJ6dnQX3mUwGfIBp0BgfH5ckqaSkBK8YM8jxeDxmJ+bUhyEEocA3hsPh0tJSsF4ggRzMFlgG3TDMUAEfgQAMPUCmhfqJRAL5sOeF9e8+yAK9WybAIrSBQMJe7Cpu2fa2KixrTN5Wj8uvDGDQA+qb+lx+w9ut+X8Bopf7VyvX6ZoAAAAASUVORK5CYII=\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABVAEwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3+jNISAMk4ArnTDJ4nMjmaaDTASiKh2mb1bPp6Um7bFwjzbuyOgM0QODIgP8AvCn1i23hbSLQYhtNrY++GO765o+y3Gjr51uxng3Zmjxyq+qj1HcDrSTfUpxpv4X96NrNFRwzR3EKzQyK8bjKspyCKkqjIKKKKACiiigDI8QXEi2kVlDnzr1xApH8IP3j+AzWnBEkECQxqFRFCgDsKySftfizGMx2dt+Ujn/4kfrW1SW9zSWkVH5hQelFMd0QDeyqCcDJxzTMzLs3TT9Vk07G2KbM1uMcf7aj6Hn8a16yNfQpZJqEcZaaycTKF6lejD8VJrUikWWJJEOVYBgfY0utinqlIfRRRTJCiiigDnfD++XWvEE7fdN2sa/8BQCuh6Vh+Hhtn1hCu1hfOT75wQf1rcqYbGtf+J935Ip32q2emy20V3OkRuZPKi3kDc3pXO/EUbPDK3W0k21zHMD6EHrUHxRsWufCX2mJc3FnOk0TDqpzjI/OrN1cx+LPh208TqPtNtubJzscdQfoQaznK/NDyOnD01F06z25rP8Ar0OljeO9sw45jmTI+hFRaYAlgkIJxCWiGf8AZJFZ3g29N94UsJG/1iR+U49GQ7T/ACqhDrl4dS1LTtNsmuHgnYmVmCoucEr9ck1XOrJ9zH2EnKUF0OtormZNT8QWbRvNphnV2wVgIbb+Ocj8iPetvT7+LUrNbmJXUEkFJBhlIOCCPWqUkzOdKUFfRryLdFFFUZmLAq2Xii6jLDF9Csyg92T5SB+BFbIrH1+0kZLfUbcFrmxfzFQfxqeHX8R/KtS2uIrq3SeFw8bjKsKS7Gk9UpfL+vkLPEs8LxMAVYEHIrkT4MubWLOnaisDzLsu4jHmKYeoGflb3FdlRUyhGW46dedPSLOWlS88N6g81nYS3mn3IBljtxl45AMbgvocCszT7rWfDc13dXulz3FhqFw1z/o43y2xbHDr1IwB0rumIVSxOABkmsm31dLvRp7zIjMbSIdpzgqSP8DUuKvvY1jVlKLvG97Jv8gh8TaTcRb4rrePQRtn8sVm6drUz3eoNZaVd3EMlwWV+EXIUA9fcfrSaH4pG27sNadbfUrPLFH4MsX8Lj1z3x3rc0ctJpyTMpUysZACMHBPGfwxTT5rag4qkpJxv8/8rFeK51udx/oFrbJnrJOXbH0AH86nFtqRyW1FAc9FgGB+ZrQpKuxg532SQEZrBeyvtFuGm0uJbixbLSWWcMresZPH/AT+Fb9IabVxRk4mbp2u2Go/LHKYp1+/bzDZKh9CprQkljiQvI6ooGSWOBUN1YWl6m26toph/wBNEBxXj/i/Sl0r4v8AhuHR9MhuftVtMz2Us5jjlKhupIIGB7dqNRrkZ6kbw6s/k2XNqGxNcZ4P+yvrWevhZ4tblnguymmzbZJbTn/WDHzD645rlfg/dR2eh6zHftb2Mv8Abs1tHbmYYRsLiNSfvc5x61J4+xqnxE8J+HdQaUaNdCaWVEcoJpFX5VJBGR7e9TyJ7lqq4NqGx3t7oumalNFNe2FtcSxfceSMMy/Q1fUBQAAAB0ArzH4c38Oja14m0CfUh9gtdSWHTvtVyGJLLkxqSckj5eO2ap+P9KsL74y+DI720huIbqGeGZJkDK6qrFQQfQsSKqxld7HrdFeWfDjWItK13xN4fn1OIaTZagttpYuZxuy24mJSxy2MDjmvU6BBRRRQAVjXvhXSNR8RWOvXNvI2pWIK28ondQgOcjaDg5yc5HNFFAFKP4feGY92NOJDX/8AaOGnkOLj++Mtwava74Z0jxNDDFq1oJxA/mQursjxt6qykEfnRRQBRX4feFkhtIl0pALS7+2xN5jlhNx85bOWPA6k9Kn1vwZoXiLUbXUdStZpLy1XbBNFdywtHznjYwwffrRRQA3/AIQbw0LS0tRpcYitLkXcWGbImH8ZbOWP1zmuhoooA//Z\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Object Summary:\n",
            "‚ùå No objects detected above threshold.\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "VvQ-YonKpeGZ",
        "outputId": "ee29210a-c696-4647-ce5f-40acd1bc0a20"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}